# Meet Kafka

모든 데이터(로그 메시지, 유저 활동 정보 등)는 의미를 담고 있고 다음으로 나아가기 위한 중요한 정보를 알려준다. 이를 알아내기 위해선 해당 데이터를 분석할 수 있는 곳에 데이터를 모아놓아야 한다. 

데이터를 더 빨리 처리할 수 있다면, 보다 더 민첩하고 신뢰성있는 서비스를 만들 수 있다. 데이터를 저장, 이동시키는 일에 더 적은 노력을 쓸수록, 비지니스에 집중할 수 있게된다. 이것이 data-driven-enterprise에서 pipeline이 아주 중요한 요소가 된 이유이다.

## Publish/Subscribe Messaging

Kafka에 대해 논하기 전에 먼저 Publish/Subscribe Messaging에 대해 이해햐는 것이 중요하다. PubSub 패턴의 송신자는 수신자를 특정하지 않고 데이터를 전달한다. 대신 Pub은 전달할 데이터를 분류하고, Sub는 분류된 데이터중 자신이 관심있는 주제의 데이터를 전달받는다. 보통 이러한 기능을 원활하게 구현하기 위해 메시지가 게시되는 중앙 지점인 Broker를 갖는다.

### How It Starts
아무개가 모니터링 정보를 수집해야 하는 어플리케이션을 만든다고 가정해보자. 처음엔 생성된 metrics를 직접적인 연결을 통해 모니터링 서버로 전달하는 방식으로 구현했다.

<img src="../img/single-direct.jpg">

- img : a single, direct metrics publisher

어플리케이션의 규모가 커짐에 따라 새로운 서비스가 추가되고 새로운 모니터링 정보가 필요할 것이다. 요구사항에 따라 변경된 어플리케이션 구조는 매우 복잡해진다. 

- img : many metrics publishers, using direct connedctions 

복잡한 데이터 흐름을 단순화하기 위해 모든 metrics를 전달받고 해당 정보가 필요한 서버들에게 데이터를 가져갈 수 있도록 하는 하나의 어플리케이션(Broker)을 둔다. 이를 통해 구조적 복잡도를 줄일 수 있다.  

- img : a metrics publish/subscribe system

### Individual Queue Systems

어플리케이션을 운영하기 위해선 metrics 정보 이외에도 서버 로그, 사용자 활동 추적 정보를 수집할 필요가 있다. 다른 정보들을 수집하기 위해 metrics 수집 구조와 유사한 개별적인 Pub/Sub 구조들을 갖게된다.  

- img : Multiple publish/subscribe systems

이 구조는 분명히 Pub/Sub 간 직접적인 연결보단 좋은 구조이다. 하지만 관리해야 할 자원의 중복이 많다. 이 구조는 개별적인 버그와 한계를 갖고 있는 여러개의 데이터 큐 시스템을 관리해야 한다. 서비스 규모에 따라 새로운 데이터 형식을 수집하게 될 수도 있다. 여기서 필요한 것은 generic(비지니스가 성장함에 따라 추가되는 데이터를 모두 관리할 수 있는) 데이터를 다루는 하나의 중앙화된 시스템이다.

## Enter Kafka

아파치 카프카는 이러한 문제를 해결하기 위해 디자인 되었다. 카프카는 보통 '분산화된 commit log', 최근에는 '분산화된 스트리밍 플랫폼'으로 소개된다. 파일시스템이나 데이터베이스에서의 commit log는 모든 변화에 대한 내구성있는 기록을 제공해서 해당 상태를 재현할 수 있도록 디자인되었다. 카프카의 데이터도 비슷하게 내구성이 있게 저장되고 읽을 수 있게 되어있다. 게다가 데이터는 시스템 내부에 분산되어 저장되기 때문에 실패에 대한 내구성이 있을뿐만 아니라 확장에 대해 열려있다.

### Messages and Batches


### Schemas


### Topics and Partitions

### Producers and Consumers

### Brokers and Clusters

### Multiple Clusters


## Why Kafka?

### Multiple Producers

카프카는 여러 topic 또는 하나의 topic을 다루는지는 상관없이 다수의 producer의 요청을 다룰 수 있다. 이 특성은 많은 프론트앤드 시스템의 데이터를 통합하고 일관성있게 유지하도록 하는 목표를 달성하게 해준다. 예를들어, 마이크로서비스를 통해 사용자에게 컨텐츠를 제공하는 사이트는 모든 서비스가 공통된 형식을 통해 하나의 조회수 topic을 가질 수 있다. 해당 topic에 대한 consumer 어플리케이션은 하나의 스트림을 통해 모든 어플리케이션의 조회수 정보를 전달받을 수 있다. 

### Multiple Consumers

카프카는 다수의 consumer가 서로의 간섭 없이 한 스트림을 읽을 수 있도록 설계되었다(consumer A가 한 스트림에서 데이터를 읽었을 때, 같은 데이터를  consumer B도 접근할 수 있도록 kafka 내에서 해당 데이터가 삭제하지 않는다). 한 클라이언트에 의해 데이터가 읽히면 다른 클라이언트는 읽을 수 없는 다른 많은 큐잉 시스템과 차별화되는 특징이다. kafka consumer들은 group으로 지정하여 한 스트림을 공유하도록 구성할 수 있다. 한 그룹 내에서는 공유하는 스트림의 데이터를 한번만 읽을 수 있도록 보장한다. 

### Disk-Based Retention

kafka는 영속성 있는 메시지를 유지하기 때문에  consumer들은 항상 실시간으로 작동할 필요가 없다. 메시지들은 각 topic마다 설정된 보존 정책(retention rule)에 따라 특정된 시간동안 kafka에 저장된다. 따라서 느린 처리 속도 또는 폭발적인 트레픽에 의해 consumer가 중단되어도 데이터를 잃을 위험이 없다. 또한 어플리게이션이 잠깐동안 멈추었을 때 producer 쪽에서 데이터를 백업해두거나 누락되게 하는 등의 작업을 신경쓰지 않아도 된다. 

### Scalable

kafka는 유연한 확장성을 갖고 있기 때문에 어떠한 규모의 데이터라도 쉽게 처리할 수 있다. 사용자는 단일  broker로 시작해서 3대의 broker로 구성된 작은 클러스터 또는 100대의 클러스터로 규모를 확장할 수 있다. 확장은 클러스터가 작동하는 동안 진행될 수 있고, 전체 시스템에 대한 가용성에는 영향이 없다. 이것은  클러스터에서 클라이언트에게 서비스하고 있는 동안 중단된 개별 broker에 대해서도 처리할 수 있다는 것을 의미한다. 더 많은 동시 중단에 견뎌야 하는 클러스터는 복제 수를 늘려서 구성할 수 있다.     

### High Performance

앞선 모든 특징들에 의해 kafka는 높은 부하에서 훌륭한 성능을 보인다. producer, consumer, broker는 아주 거대한 스트림을 다루기 위해 쉽게 스케일 아웃할 수 있다.

## The Data Ecosystem

### Usecase

#### Activity tracking

LinkedIn에서 설계했던 kafka의 본래 목적은 유저 활동을 추적하는 것이다. 유저가 프론트앤드 어플리케이션과 상호작용을 하면 해당 활동에 대한 정보가 생성된다. 이 정보는 어떤 페이지를 조회했는지, 어떤 정보를 클릭했는지 같은 정보부터 좀더 복잡한 활동에 대한 정보일 수 있다. 이러한 정보는 하나 또는 다수의 topic들로 produce 되고 백앤드 어플리케이션에서 consume 한다. 백앤드 어플리케이션은 이러한 정보를 모아 리포트를 만들거나, 머신러닝에 사용하거나 검색결과에 사용하는 등, 풍부한 사용자 경험을 위해 사용된다.

#### Messaging

kafka는 사용자에게 이메일같은 알림을 보내야 하는 어플리케이션의 메시징 시스템으로도 사용된다. 이러한 어플리케이션들은 알림 형식이나 실제로 유저에게 메시지를 전달할 방법에 대해서는 고려하지 않고 그저 내용을 kafka에 produce한다. 이러한 메시지를 처리하는 어플리케이션에서는 kafka에서 메시지를 읽어와서 유저에게 알림을 보내는 등의 처리를 한다.

이러한 구조를 통해 다양한 형식의 알림을 보내야하는 다수의 어플리케이션에서 각각 알림을 처리하는 중복성을 피할 수 있다.                                                                                                                                   

#### Metrics and logging

kafka는 어플리케이션이나 시스템의 metrics 또는 logs를 수집하는 것에 이상적인 구조이다. 이러한 유즈케이스에서는 다수의 어플리케이션이 같은 형식의 메시지를 생성하는 구조이다. 어플리케이션들은 kafka topic에 약속된 형태의 metrics를 전송하고 모니터링과 알림 시스템에서 해당 정보들을 수신받는다. 로그의 경우에는 elasticsearch 같은 시스템에 라우팅해서 로그 분석, 조회에 사용할 수 있다. 

이 구조에서의 또다른 장점은 만약 로그가 최종 저장되는 시스템에 변경사항이 있는 경우, kafka 앞쪽에 있는 프론트앤드 어플리케이션은 수정할 필요가 없다는 것이다.

#### Commit log

kafka는 commit-log 개념을 기반으로 만들어졌기 때문에, 데이터베이스의 변화를 전달해서 어플리케이션이 변경사항을 알 수 있도록 하는 방식으로도 사용할 수 있다. 이 changelog 스트림은 데이터베이스의 변경사항을 원격 시스템에 복제하거나 여러 변경사항을 하나의 뷰로 통합하는 방식으로 활용할 수 있다.

#### Stream processing

kafka의 거의 대부분의 사용사례는 스트림 처리라고 볼 수 있다. 

stream processing은 일반적으로 hadoop의 map/reduce 처리와 비슷한 기능을 하는 어플리케이션으로 묘사된다. hadoop은 보통 시간 또는 일 단위의 긴 시간에 걸친 데이터 집합을 다룬다. 반면에 스트림 처리는 메시지가 생성되는 즉시 실시간으로 데이터를 처리한다. 

## Kafka's Origin

kafka는 LinkedIn에서 데이터 파이프라인 문제를 해결하기 위해 만들어졌다. kafka는 많은 형식의 데이터를 다룰 수 있는 고성능의 메시징 시스템을 위해 설계되었다.

### LinkedIn's Problem

### The Birth of Kafka

- push-pull 모델을 통해 producer와 consumer 간의 결합도를 낮추기
- 다수의 consumer를 지원하기 위해 메시지 데이터에 대한 영속성 제공하기
- 높은 처리량을 위한 최적화
- 데이터 스트림의 규모가 성장함에 따라 시스템을 수평적으로 확장할 수 있게 하기

### Open Source

### The Name

 
