# Meet Kafka

모든 데이터(로그 메시지, 유저 활동 정보 등)는 의미를 담고 있고 다음으로 나아가기 위한 중요한 정보를 알려준다. 이를 알아내기 위해선 해당 데이터를 분석할 수 있는 곳에 데이터를 모아놓아야 한다. 

데이터를 더 빨리 처리할 수 있다면, 보다 더 민첩하고 신뢰성있는 서비스를 만들 수 있다. 데이터를 저장, 이동시키는 일에 더 적은 노력을 쓸수록, 비지니스에 집중할 수 있게된다. 이것이 data-driven-enterprise에서 pipeline이 아주 중요한 요소가 된 이유이다.

## Publish/Subscribe Messaging

Kafka에 대해 논하기 전에 먼저 Publish/Subscribe Messaging에 대해 이해햐는 것이 중요하다. PubSub 패턴의 송신자는 수신자를 특정하지 않고 데이터를 전달한다. 대신 Pub은 전달할 데이터를 분류하고, Sub는 분류된 데이터중 자신이 관심있는 주제의 데이터를 전달받는다. 보통 이러한 기능을 원활하게 구현하기 위해 메시지가 게시되는 중앙 지점인 Broker를 갖는다.

### How It Starts
아무개가 모니터링 정보를 수집해야 하는 어플리케이션을 만든다고 가정해보자. 처음엔 생성된 metrics를 직접적인 연결을 통해 모니터링 서버로 전달하는 방식으로 구현했다.

<img src="../img/single-direct.jpg">

- img : a single, direct metrics publisher

어플리케이션의 규모가 커짐에 따라 새로운 서비스가 추가되고 새로운 모니터링 정보가 필요할 것이다. 요구사항에 따라 변경된 어플리케이션 구조는 매우 복잡해진다. 

- img : many metrics publishers, using direct connedctions 

복잡한 데이터 흐름을 단순화하기 위해 모든 metrics를 전달받고 해당 정보가 필요한 서버들에게 데이터를 가져갈 수 있도록 하는 하나의 어플리케이션(Broker)을 둔다. 이를 통해 구조적 복잡도를 줄일 수 있다.  

- img : a metrics publish/subscribe system

### Individual Queue Systems

어플리케이션을 운영하기 위해선 metrics 정보 이외에도 서버 로그, 사용자 활동 추적 정보를 수집할 필요가 있다. 다른 정보들을 수집하기 위해 metrics 수집 구조와 유사한 개별적인 Pub/Sub 구조들을 갖게된다.  

- img : Multiple publish/subscribe systems

이 구조는 분명히 Pub/Sub 간 직접적인 연결보단 좋은 구조이다. 하지만 관리해야 할 자원의 중복이 많다. 이 구조는 개별적인 버그와 한계를 갖고 있는 여러개의 데이터 큐 시스템을 관리해야 한다. 서비스 규모에 따라 새로운 데이터 형식을 수집하게 될 수도 있다. 여기서 필요한 것은 generic(비지니스가 성장함에 따라 추가되는 데이터를 모두 관리할 수 있는) 데이터를 다루는 하나의 중앙화된 시스템이다.

## Enter Kafka

아파치 카프카는 이러한 문제를 해결하기 위해 디자인 되었다. 카프카는 보통 '분산화된 commit log', 최근에는 '분산화된 스트리밍 플랫폼'으로 소개된다. 파일시스템이나 데이터베이스에서의 commit log는 모든 변화에 대한 내구성있는 기록을 제공해서 해당 상태를 재현할 수 있도록 디자인되었다. 카프카의 데이터도 비슷하게 내구성이 있게 저장되고 읽을 수 있게 되어있다. 게다가 데이터는 시스템 내부에 분산되어 저장되기 때문에 실패에 대한 내구성이 있을뿐만 아니라 확장에 대해 열려있다.

### Messages and Batches


### Schemas


### Topics and Partitions

### Producers and Consumers

### Brokers and Clusters

### Multiple Clusters


## Why Kafka?

### Multiple Producers

카프카는 여러 topic 또는 하나의 topic을 다루는지는 상관없이 다수의 producer의 요청을 다룰 수 있다. 이 특성은 많은 프론트앤드 시스템의 데이터를 통합하고 일관성있게 유지하도록 하는 목표를 달성하게 해준다. 예를들어, 마이크로서비스를 통해 사용자에게 컨텐츠를 제공하는 사이트는 모든 서비스가 공통된 형식을 통해 하나의 조회수 topic을 가질 수 있다. 해당 topic에 대한 consumer 어플리케이션은 하나의 스트림을 통해 모든 어플리케이션의 조회수 정보를 전달받을 수 있다. 

### Multiple Consumers

카프카는 다수의 consumer가 서로의 간섭 없이 한 스트림을 읽을 수 있도록 설계되었다(consumer A가 한 스트림에서 데이터를 읽었을 때, 같은 데이터를  consumer B도 접근할 수 있도록 kafka 내에서 해당 데이터가 삭제하지 않는다). 한 클라이언트에 의해 데이터가 읽히면 다른 클라이언트는 읽을 수 없는 다른 많은 큐잉 시스템과 차별화되는 특징이다. kafka consumer들은 group으로 지정하여 한 스트림을 공유하도록 구성할 수 있다. 한 그룹 내에서는 공유하는 스트림의 데이터를 한번만 읽을 수 있도록 보장한다. 

### Disk-Based Retention

kafka는 영속성 있는 메시지를 유지하기 때문에  consumer들은 항상 실시간으로 작동할 필요가 없다. 메시지들은 각 topic마다 설정된 보존 정책(retention rule)에 따라 특정된 시간동안 kafka에 저장된다. 따라서 느린 처리 속도 또는 폭발적인 트레픽에 의해 consumer가 중단되어도 데이터를 잃을 위험이 없다. 또한 어플리게이션이 잠깐동안 멈추었을 때 producer 쪽에서 데이터를 백업해두거나 누락되게 하는 등의 작업을 신경쓰지 않아도 된다. 

### Scalable

kafka는 유연한 확장성을 갖고 있기 때문에 어떠한 규모의 데이터라도 쉽게 처리할 수 있다. 사용자는 단일  broker로 시작해서 3대의 broker로 구성된 작은 클러스터 또는 100대의 클러스터로 규모를 확장할 수 있다. 확장은 클러스터가 작동하는 동안 진행될 수 있고, 전체 시스템에 대한 가용성에는 영향이 없다. 이것은  클러스터에서 클라이언트에게 서비스하고 있는 동안 중단된 개별 broker에 대해서도 처리할 수 있다는 것을 의미한다. 더 많은 동시 중단에 견뎌야 하는 클러스터는 복제 수를 늘려서 구성할 수 있다.     

### High Performance

앞선 모든 특징들에 의해 kafka는 높은 부하에서 훌륭한 성능을 보인다. producer, consumer, broker는 아주 거대한 스트림을 다루기 위해 쉽게 스케일 아웃할 수 있다.

## The Data Ecosystem

 
